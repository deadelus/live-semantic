
# ğŸ¥ LiveSemantic

[![Go Version](https://img.shields.io/badge/Go-1.21+-00ADD8?logo=go)](https://golang.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Build Status](https://img.shields.io/badge/Build-Passing-brightgreen)](https://github.com/your-org/livesemantic)

**Real-time semantic video analysis with natural language AI filters**

LiveSemantic analyzes video streams and files using AI-powered semantic understanding. Define any filter in natural language ("person walking", "red car entering", "crowd gathering") and get instant matches with sub-50ms latency.

## ğŸš€ **Quick Start**

### Installation
```bash
# Download latest release
wget https://github.com/your-org/livesemantic/releases/latest/livesemantic
chmod +x livesemantic

# Or build from source
git clone https://github.com/your-org/livesemantic.git
cd livesemantic
make build
```

### Setup AI Models
```bash
# Export ONNX models (one-time setup)
python scripts/export_clip_onnx.py

# Verify installation
./livesemantic --version
```

### Basic Usage
```bash
# Real-time webcam surveillance
./livesemantic realtime \
  --source="cam0" \
  --filter="person walking,vehicle entering" \
  --threshold=0.7

# Batch video file analysis  
./livesemantic batch \
  --file="video.mp4" \
  --filters="celebration,applause,dancing" \
  --export-clips
```

## ğŸ¯ **Use Cases**

### ğŸ” **Security Surveillance**
Monitor live camera feeds with intelligent alerts for security events.

```bash
./livesemantic realtime \
  --source="rtmp://camera.local/stream" \
  --filter="unauthorized person,vehicle in restricted area" \
  --alert="webhook,slack" \
  --mode=security
```

### ğŸ¬ **Content Creation**
Automatically extract highlights from long video content.

```bash
./livesemantic batch \
  --file="wedding_ceremony.mp4" \
  --filters="bride smiling,applause,emotional moments" \
  --output="highlights/" \
  --quality=high
```

### ğŸ“Š **Video Analytics**
Index and search large video libraries by semantic content.

```bash
./livesemantic batch \
  --directory="/video/library/" \
  --filters="sports,celebration,crowd" \
  --index-database \
  --workers=4
```

## âš¡ **Performance**

- **Ultra-low latency**: < 20ms inference with ONNX
- **High throughput**: Process multiple video streams simultaneously  
- **Memory efficient**: Optimized buffering and garbage collection
- **Scalable**: Horizontal scaling with container orchestration

### Benchmarks
| Mode | Latency | Throughput | Resource Usage |
|------|---------|------------|----------------|
| Realtime | 5-20ms | 30 FPS | 200MB RAM |
| Batch | 10-30ms | 2x video speed | 500MB RAM |

## ğŸ—ï¸ **Architecture**

LiveSemantic follows Clean Architecture principles with pluggable components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Transport     â”‚  Command-line interface
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Application       â”‚  Use cases, business logic
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  
â”‚     Domain          â”‚  Core entities, ports
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Infrastructure     â”‚  ONNX AI, Video, Storage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components
- **AI Engine**: ONNX-optimized CLIP models for semantic understanding
- **Video Pipeline**: Concurrent frame processing with gocv
- **Alert System**: Pluggable notifications (console, webhook, Slack)
- **Monitoring**: Built-in metrics and observability

## ğŸ§  **AI Models**

### Supported Models
- **CLIP**: Text-image semantic matching
- **Custom ONNX**: Bring your own exported models
- **Future**: Grounding DINO, BLIP, custom transformers

### Model Performance
| Model | Size | Inference Time | Use Case |
|-------|------|---------------|----------|
| CLIP ViT-B/32 | 150MB | 5-10ms | General purpose |
| CLIP ViT-L/14 | 430MB | 15-25ms | High accuracy |
| Custom ONNX | Variable | Variable | Specialized tasks |

## ğŸ“– **Documentation**

### Configuration
```yaml
# config/local.yaml
mode: "realtime"
video:
  fps: 10
  resolution: "720p"
  buffer_size: 10

ai:
  provider: "onnx"
  model_path: "models/clip_text.onnx"
  confidence_threshold: 0.7

alerts:
  channels:
    - type: "console"
    - type: "webhook"
      url: "https://api.example.com/alerts"
```

### API Reference
See [docs/API.md](docs/API.md) for detailed API documentation.

### Examples
Check [examples/](examples/) directory for common usage patterns.

## ğŸ”§ **Development**

### Prerequisites
- Go 1.21+
- Python 3.9+ (for model export)
- OpenCV 4.x
- ONNX Runtime

### Build
```bash
# Install dependencies
make deps

# Run tests
make test

# Build optimized binary
make build-release

# Development build with debugging
make build-dev
```

### Project Structure
```
livesemantic/
â”œâ”€â”€ cmd/livesemantic/     # CLI application entry point
â”œâ”€â”€ internal/             # Private application code
â”‚   â”œâ”€â”€ domain/          # Business entities and rules
â”‚   â”œâ”€â”€ application/     # Use cases and services  
â”‚   â”œâ”€â”€ infrastructure/  # External integrations
â”‚   â””â”€â”€ transport/       # User interfaces
â”œâ”€â”€ models/              # ONNX model files
â”œâ”€â”€ configs/             # Configuration templates
â”œâ”€â”€ scripts/             # Utility scripts
â””â”€â”€ docs/                # Documentation
```

## ğŸ¤ **Contributing**

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Quick Contribution Guide
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Workflow
- Follow [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html) principles
- Write tests for new features
- Update documentation for API changes
- Run `make lint` before committing

## ğŸ“Š **Monitoring & Observability**

### Built-in Metrics
- Processing latency per frame
- Match detection rate
- AI model performance
- Memory and CPU usage

### Prometheus Integration
```bash
# Enable Prometheus metrics
./livesemantic realtime \
  --source="cam0" \
  --filter="person" \
  --metrics-prometheus \
  --metrics-port=9090
```

### Grafana Dashboard
Import the provided [Grafana dashboard](configs/grafana-dashboard.json) for visualization.

## ğŸš€ **Deployment**

### Docker
```bash
# Build image
docker build -t livesemantic:latest .

# Run container
docker run -d \
  --name livesemantic \
  -v /dev/video0:/dev/video0 \
  -p 8080:8080 \
  livesemantic:latest realtime --source="cam0"
```

### Kubernetes
```bash
# Deploy to cluster
kubectl apply -f deployments/k8s/

# Scale horizontally
kubectl scale deployment livesemantic --replicas=3
```

### Cloud Platforms
- **AWS**: Lambda for batch, ECS for realtime
- **GCP**: Cloud Run for batch, GKE for realtime  
- **Azure**: Container Instances for batch, AKS for realtime

## ğŸ”’ **Security**

### Best Practices
- Run with minimal privileges
- Secure webhook endpoints with authentication
- Regular security updates for dependencies
- Network isolation in production

### Compliance
- GDPR: No personal data stored by default
- SOC 2: Audit logs available
- HIPAA: Configurable data retention policies

## ğŸ“ˆ **Roadmap**

### v1.0 - Foundation âœ…
- [x] ONNX AI integration
- [x] Realtime video processing
- [x] CLI interface
- [x] Basic alerting

### v1.1 - Performance ğŸš§
- [ ] GPU acceleration
- [ ] Distributed processing
- [ ] Advanced caching
- [ ] Load balancing

### v1.2 - Features ğŸ“‹
- [ ] Web UI interface
- [ ] Advanced AI models
- [ ] Video clip export
- [ ] Search API

### v2.0 - Enterprise ğŸ¯
- [ ] Multi-tenant support
- [ ] Advanced analytics
- [ ] Custom model training
- [ ] Enterprise integrations

## ğŸ“ **Support**

- **Documentation**: [docs.livesemantic.io](https://docs.livesemantic.io)
- **Issues**: [GitHub Issues](https://github.com/your-org/livesemantic/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/livesemantic/discussions)
- **Email**: support@livesemantic.io

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- [OpenAI CLIP](https://github.com/openai/CLIP) for the foundational AI model
- [ONNX Runtime](https://onnxruntime.ai/) for optimized inference
- [GoCV](https://gocv.io/) for computer vision capabilities
- The open-source community for inspiration and contributions

---

**Built with â¤ï¸ for intelligent video analysis**
